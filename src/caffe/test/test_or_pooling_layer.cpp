#include <vector>

#include "gtest/gtest.h"

#include "caffe/blob.hpp"
#include "caffe/common.hpp"
#include "caffe/filler.hpp"
#include "caffe/layers/or_pooling_layer.hpp"
#include "caffe/layers/pooling_layer.hpp"

#ifdef USE_CUDNN
//#include "caffe/layers/cudnn_pooling_layer.hpp"
#endif

#include "caffe/test/test_caffe_main.hpp"
#include "caffe/test/test_gradient_check_util.hpp"

namespace caffe {

template <typename TypeParam>
class OrPoolingLayerTest : public MultiDeviceTest<TypeParam> {
  typedef typename TypeParam::Dtype Dtype;

 protected:
  OrPoolingLayerTest()
      : blob_bottom_(new Blob<Dtype>()),
        blob_top_(new Blob<Dtype>()),
        blob_top_mask_(new Blob<Dtype>()) {}
  virtual void SetUp() {
    Caffe::set_random_seed(1701);
    blob_bottom_->Reshape(2, 4, 3, 3);
    // fill the values
    FillerParameter filler_param;
    GaussianFiller<Dtype> filler(filler_param);
    filler.Fill(this->blob_bottom_);
    blob_bottom_vec_.push_back(blob_bottom_);
    blob_top_vec_.push_back(blob_top_);
  }
  virtual ~OrPoolingLayerTest() {
    delete blob_bottom_;
    delete blob_top_;
    delete blob_top_mask_;
  }
  Blob<Dtype>* const blob_bottom_;
  Blob<Dtype>* const blob_top_;
  Blob<Dtype>* const blob_top_mask_;
  vector<Blob<Dtype>*> blob_bottom_vec_;
  vector<Blob<Dtype>*> blob_top_vec_;
  // Test for 2x 2 square pooling layer
  // Test for 3x 2 rectangular pooling layer with kernel_h > kernel_w
  void TestForwardRectHigh() {
    LayerParameter layer_param;
    PoolingParameter* pooling_param = layer_param.mutable_pooling_param();
    pooling_param->set_kernel_h(4);
    pooling_param->set_kernel_w(4);
    pooling_param->set_pool(PoolingParameter_PoolMethod_MAX);
    const int num = 2;
    const int channels = 4;
    blob_bottom_->Reshape(num, channels, 3, 3);
    // Input: 2 num of 4 x 3 x3:
    // [35     1     6]
    // [ 3    32     7]
    // [31     9     2]

    // [26    19    24]
    // [21    23    25]
    // [22    27    20]

    // [ 8    28    33]
    // [30     5    34]
    // [ 4    36    29]

    // [17    10    15]
    // [12    14    16]
    // [13    18    11]
    // (this is generated by magic(6) in MATLAB)
    for (int i = 0; i < 36 * num; i += 36) {
      blob_bottom_->mutable_cpu_data()[i +  0] = 35;
      blob_bottom_->mutable_cpu_data()[i +  1] = 1;
      blob_bottom_->mutable_cpu_data()[i +  2] = 6;
      blob_bottom_->mutable_cpu_data()[i +  3] = 3;
      blob_bottom_->mutable_cpu_data()[i +  4] = 32;
      blob_bottom_->mutable_cpu_data()[i +  5] = 7;
      blob_bottom_->mutable_cpu_data()[i +  6] = 31;
      blob_bottom_->mutable_cpu_data()[i +  7] = 9;
      blob_bottom_->mutable_cpu_data()[i +  8] = 2;
      blob_bottom_->mutable_cpu_data()[i +  9] = 26;
      blob_bottom_->mutable_cpu_data()[i + 10] = 19;
      blob_bottom_->mutable_cpu_data()[i + 11] = 24;
      blob_bottom_->mutable_cpu_data()[i + 12] = 21;
      blob_bottom_->mutable_cpu_data()[i + 13] = 23;
      blob_bottom_->mutable_cpu_data()[i + 14] = 25;
      blob_bottom_->mutable_cpu_data()[i + 15] = 22;
      blob_bottom_->mutable_cpu_data()[i + 16] = 27;
      blob_bottom_->mutable_cpu_data()[i + 17] = 20;
      blob_bottom_->mutable_cpu_data()[i + 18] = 8;
      blob_bottom_->mutable_cpu_data()[i + 19] = 28;
      blob_bottom_->mutable_cpu_data()[i + 20] = 33;
      blob_bottom_->mutable_cpu_data()[i + 21] = 30;
      blob_bottom_->mutable_cpu_data()[i + 22] = 5;
      blob_bottom_->mutable_cpu_data()[i + 23] = 34;
      blob_bottom_->mutable_cpu_data()[i + 24] = 4;
      blob_bottom_->mutable_cpu_data()[i + 25] = 36;
      blob_bottom_->mutable_cpu_data()[i + 26] = 29;
      blob_bottom_->mutable_cpu_data()[i + 27] = 17;
      blob_bottom_->mutable_cpu_data()[i + 28] = 10;
      blob_bottom_->mutable_cpu_data()[i + 29] = 15;
      blob_bottom_->mutable_cpu_data()[i + 30] = 12;
      blob_bottom_->mutable_cpu_data()[i + 31] = 14;
      blob_bottom_->mutable_cpu_data()[i + 32] = 16;
      blob_bottom_->mutable_cpu_data()[i + 33] = 13;
      blob_bottom_->mutable_cpu_data()[i + 34] = 18;
      blob_bottom_->mutable_cpu_data()[i + 35] = 11;
    }
    OrPoolingLayer<Dtype> layer(layer_param);
    layer.SetUp(blob_bottom_vec_, blob_top_vec_);
    EXPECT_EQ(blob_top_->num(), num);
    EXPECT_EQ(blob_top_->channels(), channels / 4);
    EXPECT_EQ(blob_top_->height(), 3);
    EXPECT_EQ(blob_top_->width(), 3);
    if (blob_top_vec_.size() > 1) {
      EXPECT_EQ(blob_top_mask_->num(), num);
      EXPECT_EQ(blob_top_mask_->channels(), channels / 4);
      EXPECT_EQ(blob_top_mask_->height(), 3);
      EXPECT_EQ(blob_top_mask_->width(), 3);
    }
    layer.Forward_gpu(blob_bottom_vec_, blob_top_vec_);
    // Expected output: 2x 2 channels of:
    // [35    28    33]
    // [30    32    34]
    // [31    36    29]
    for (int i = 0; i < 9 * num * 1; i += 9) {
      EXPECT_EQ(blob_top_->cpu_data()[i +  0], 35);
      EXPECT_EQ(blob_top_->cpu_data()[i +  1], 28);
      EXPECT_EQ(blob_top_->cpu_data()[i +  2], 33);
      EXPECT_EQ(blob_top_->cpu_data()[i +  3], 30);
      EXPECT_EQ(blob_top_->cpu_data()[i +  4], 32);
      EXPECT_EQ(blob_top_->cpu_data()[i +  5], 34);
      EXPECT_EQ(blob_top_->cpu_data()[i +  6], 31);
      EXPECT_EQ(blob_top_->cpu_data()[i +  7], 36);
      EXPECT_EQ(blob_top_->cpu_data()[i +  8], 29);

    }
    if (blob_top_vec_.size() > 1) {
        // [ 0     2     2]
        // [ 2     0     2]
        // [ 0     2     2]
      for (int i = 0; i < 9 * num * 1; i += 9) {
        EXPECT_EQ(blob_top_mask_->cpu_data()[i +  0],  0);
        EXPECT_EQ(blob_top_mask_->cpu_data()[i +  1],  2);
        EXPECT_EQ(blob_top_mask_->cpu_data()[i +  2],  2);
        EXPECT_EQ(blob_top_mask_->cpu_data()[i +  3],  2);
        EXPECT_EQ(blob_top_mask_->cpu_data()[i +  4],  0);
        EXPECT_EQ(blob_top_mask_->cpu_data()[i +  5],  2);
        EXPECT_EQ(blob_top_mask_->cpu_data()[i +  6],  0);
        EXPECT_EQ(blob_top_mask_->cpu_data()[i +  7],  2);
        EXPECT_EQ(blob_top_mask_->cpu_data()[i +  8],  2);

      }
    }
    for (int i = 0; i < 9 * num; i += 9) {
        blob_top_->mutable_cpu_diff()[i + 0] = i + 0;
        blob_top_->mutable_cpu_diff()[i + 1] = i + 1;
        blob_top_->mutable_cpu_diff()[i + 2] = i + 2;
        blob_top_->mutable_cpu_diff()[i + 3] = i + 3;
        blob_top_->mutable_cpu_diff()[i + 4] = i + 4;
        blob_top_->mutable_cpu_diff()[i + 5] = i + 5;
        blob_top_->mutable_cpu_diff()[i + 6] = i + 6;
        blob_top_->mutable_cpu_diff()[i + 7] = i + 7;
        blob_top_->mutable_cpu_diff()[i + 8] = i + 8;
    }
    const std::vector<bool> pb = {true};
    layer.Backward(this->blob_top_vec_, pb, this->blob_bottom_vec_);
    for (int i = 0; i < 9 * num * 4; i += 36) {
        const Dtype* diff = blob_bottom_->cpu_diff();
        printf("%f  %f  %f\n", diff[i+0], diff[i+1], diff[i+2]);
        printf("%f  %f  %f\n", diff[i+3], diff[i+4], diff[i+5]);
        printf("%f  %f  %f\n", diff[i+6], diff[i+7], diff[i+8]);

        printf("%f  %f  %f\n", diff[i+9], diff[i+10], diff[i+11]);
        printf("%f  %f  %f\n", diff[i+12], diff[i+13], diff[i+14]);
        printf("%f  %f  %f\n", diff[i+15], diff[i+16], diff[i+17]);


        printf("%f  %f  %f\n", diff[i+18], diff[i+19], diff[i+20]);
        printf("%f  %f  %f\n", diff[i+21], diff[i+22], diff[i+23]);
        printf("%f  %f  %f\n", diff[i+24], diff[i+25], diff[i+26]);

        printf("%f  %f  %f\n", diff[i+27], diff[i+28], diff[i+29]);
        printf("%f  %f  %f\n", diff[i+30], diff[i+31], diff[i+32]);
        printf("%f  %f  %f\n", diff[i+33], diff[i+34], diff[i+35]);

        cout << "--------------------------\n";
    }
  }
};

TYPED_TEST_CASE(OrPoolingLayerTest, TestDtypesAndDevices);

TYPED_TEST(OrPoolingLayerTest, TestSetup) {
  typedef typename TypeParam::Dtype Dtype;
  LayerParameter layer_param;
  PoolingParameter* pooling_param = layer_param.mutable_pooling_param();
  pooling_param->set_kernel_size(4);
  pooling_param->set_stride(2);
  OrPoolingLayer<Dtype> layer(layer_param);
  layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
  EXPECT_EQ(this->blob_top_->num(), this->blob_bottom_->num());
  EXPECT_EQ(this->blob_top_->channels() * 4, this->blob_bottom_->channels());
  EXPECT_EQ(this->blob_top_->height(), 3);
  EXPECT_EQ(this->blob_top_->width(), 3);
}

/*
TYPED_TEST(OrPoolingLayerTest, PrintBackward) {
  typedef typename TypeParam::Dtype Dtype;
  LayerParameter layer_param;
  PoolingParameter* pooling_param = layer_param.mutable_pooling_param();  
  pooling_param->set_kernel_size(4);
  pooling_param->set_stride(2);
  OrPoolingLayer<Dtype> layer(layer_param);
  layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
  layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
  for (int i = 0; i < this->blob_bottom_->count(); ++i) {
    cout << "bottom data " << i << " " << this->blob_bottom_->cpu_data()[i] << endl;
  }
  for (int i = 0; i < this->blob_top_->count(); ++i) {
    cout << "top data " << i << " " << this->blob_top_->cpu_data()[i] << endl;
  }

  for (int i = 0; i < this->blob_top_->count(); ++i) {
    this->blob_top_->mutable_cpu_diff()[i] = i;
  }
  const std::vector<bool> pb = {true};
  layer.Backward(this->blob_top_vec_, pb, this->blob_bottom_vec_);
  for (int i = 0; i < this->blob_bottom_->count(); ++i) {
    cout << "bottom diff " << i << " " << this->blob_bottom_->cpu_diff()[i] << endl;
  }
}
*/

TYPED_TEST(OrPoolingLayerTest, TestForwardMax) {
//  this->TestForwardSquare();
  this->TestForwardRectHigh();
//  this->TestForwardRectWide();
}

/*
TYPED_TEST(OrPoolingLayerTest, TestForwardMaxTopMask) {
  this->blob_top_vec_.push_back(this->blob_top_mask_);
//  this->TestForwardSquare();
  this->TestForwardRectHigh();
//  this->TestForwardRectWide();
}
*/
/*
TYPED_TEST(OrPoolingLayerTest, TestGradientMax) {
  typedef typename TypeParam::Dtype Dtype;
  for (int kernel_h = 3; kernel_h <= 4; kernel_h++) {
    for (int kernel_w = 3; kernel_w <= 4; kernel_w++) {
      LayerParameter layer_param;
      PoolingParameter* pooling_param = layer_param.mutable_pooling_param();
      pooling_param->set_kernel_h(kernel_h);
      pooling_param->set_kernel_w(kernel_w);
      pooling_param->set_stride(2);
      pooling_param->set_pad(1);
      pooling_param->set_pool(PoolingParameter_PoolMethod_MAX);
      OrPoolingLayer<Dtype> layer(layer_param);
      GradientChecker<Dtype> checker(0e-4, 1e-2);
      checker.CheckGradientExhaustive(&layer, this->blob_bottom_vec_,
          this->blob_top_vec_);
    }
  }
}
*/

}  // namespace caffe
